{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "from sklearn.preprocessing import normalize,StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error,accuracy_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.naive_bayes import GaussianNB,BernoulliNB,ComplementNB,MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "",
    "_uuid": ""
   },
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\"../input/workingcsv/dsf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**modifying the sgpa,tenth grade into percentages**\n",
    "# saving the dataframe \n",
    "df.to_csv(r'C:\\Users\\Admin\\Desktop\\file3.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_data = df.rename(columns = {\"G1\": \"Tenth\", \n",
    "                                  #\"G2\":\"Twelfth\", \n",
    "                                  #\"G3\": \"Final\",\"goout\":\"social\",\"paid\":\"tution\"}) \n",
    "df[\"SGPA4\"]=((df[\"SGPA4\"]-0.5)*10)\n",
    "df[\"SGPA4\"].head()\n",
    "df[\"SGPA3\"]=(df[\"SGPA3\"]-0.5)*10\n",
    "df[\"SGPA3\"].head()\n",
    "df[\"SGPA2\"]=(df[\"SGPA2\"]-0.5)*10\n",
    "df[\"SGPA2\"].head()\n",
    "df[\"SGPA1\"]=(df[\"SGPA1\"]-0.5)*10\n",
    "df[\"SGPA1\"].head()\n",
    "df[\"tenth\"]=(df[\"tenth\"]*10)\n",
    "df[\"tenth\"].head()\n",
    "#new_data\n",
    "#saving the dataframe \n",
    "#new_data.to_csv('refined1.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checking for missing values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**to show skewness in data**\n",
    "If the skewness is between -0.5 and 0.5, the data are fairly symmetrical.\n",
    "If the skewness is between -1 and -0.5(negatively skewed) or between 0.5 and 1(positively skewed), the data are moderately skewed.\n",
    "If the skewness is less than -1(negatively skewed) or greater than 1(positively skewed), the data are highly skewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.skew(axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To find the realtionship of all the numerical attributes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"tenth\"] = np.sqrt(df[\"tenth\"])\n",
    "df[\"tenth\"].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Twelfth\"] = np.log(df[\"Twelfth\"])\n",
    "df[\"Twelfth\"].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"SGPA1\"] = np.log(df[\"SGPA1\"])\n",
    "df[\"SGPA1\"].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"SGPA2\"] = np.log(df[\"SGPA2\"])\n",
    "df[\"SGPA2\"].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"attendance\"] = np.sqrt(df[\"attendance\"])\n",
    "df[\"attendance\"].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"BACKLOGS\"] = np.sqrt(df[\"BACKLOGS\"])\n",
    "df[\"BACKLOGS\"].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.kurtosis(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.get_dummies(df, columns = [\"gender\",\"addresstype\",\"Mjob\",\"Fjob\",\"coactivities\"],drop_first=True)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***NORMALISING DATA AND STANDARDISING DATA TO REMOVE OUTLIERS in standardisation transform(self, X[, copy]) Perform standardization by centering and scaling fit_transform(self, X[, y]) Fit to data, then transform it.\n",
    "\n",
    "splitting the data into dependent and independent sets\n",
    "\n",
    "**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(df1)\n",
    "scaler.transform(df1)\n",
    "nm = normalize(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation matrix\n",
    "corrmat = df1.corr()\n",
    "f, ax = plt.subplots(figsize=(150, 50))\n",
    "sns.set(font_scale=1.25)\n",
    "sns.heatmap(corrmat, annot=True, vmax=1.0, square=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df1.columns\n",
    "df1 = pd.DataFrame(nm, columns = cols)\n",
    "x = df1.drop([\"SGPA4\"], axis = 1)\n",
    "y = df1[[\"SGPA4\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.2, random_state =10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh = KNeighborsRegressor()\n",
    "neigh.fit(x_train, y_train)\n",
    "y_pred = neigh.predict(x_test) \n",
    "print(\"R square error =\",r2_score(y_test, y_pred))\n",
    "print(\"Mean square error\", mean_squared_error(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm \n",
    "model4 = sm.OLS(y, x, data = df1).fit()\n",
    "#model_predict = model4.predict(x_test)\n",
    "models_details = model4.summary()\n",
    "print(models_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr2=DecisionTreeRegressor()\n",
    "regr2.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr2.fit(x, y)\n",
    "y_pred = regr2.predict(x_test)\n",
    "print(\"R square error =\",r2_score(y_test, y_pred))\n",
    "print(\"Mean square error\", mean_squared_error(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor()\n",
    "regr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regr.predict(x_test)\n",
    "print(\"R square error =\",r2_score(y_test, y_pred))\n",
    "print(\"Mean square error = \", mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_price(tenth,Twelfth,SGPA1,SGPA2,SGPA3,BACKLOGS,attendance):    \n",
    "    #loc_index = np.where(x.columns==tenth)\n",
    "    X = np.zeros(len(x.columns))\n",
    "    X[0]=Twelfth\n",
    "    X[1]=SGPA1\n",
    "    X[2]=SGPA2\n",
    "    X[3]=SGPA3\n",
    "    X[4]=BACKLOGS\n",
    "    X[5]=attendance\n",
    "    #if loc_index >= 0:\n",
    "        #X[loc_index] = 1\n",
    "\n",
    "    return regr.predict([X])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re=predict_price(9.5,85,9.7,9.8,8.1,0,98)\n",
    "re*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=predict_price(9.7,97,8.8,8.51,8.37,0,98)\n",
    "r*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image  \n",
    "from sklearn import tree\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_count = 0\n",
    "for tree_in_random_forest in regr.estimators_:\n",
    "    if (tree_count ==1):        \n",
    "        rfr_file = tree.export_graphviz(tree_in_random_forest, out_file=None)\n",
    "        rfr_graph = graphviz.graph_from_dot_data(rfr_file)        \n",
    "    tree_count = tree_count + 1\n",
    "Image(rfr_graph.create_png())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm \n",
    "model4 = sm.OLS(y, x, data = df1).fit()\n",
    "#model_predict = model4.predict(x_test)\n",
    "models_details = model4.summary()\n",
    "print(models_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the model on training set \n",
    "gnb = GaussianNB() \n",
    "gnb.fit(x_train,y_train) \n",
    "\n",
    "  \n",
    "# making predictions on the testing set \n",
    "y_pred = gnb.predict(x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
